{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YvE1PbupiFlTCa2bHtn9tXHAFeMCCJlD",
      "authorship_tag": "ABX9TyPYTD+TZ79GI7atxevcyWz9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gRedDeer/kaggle_notebooks/blob/main/Mnist_digit_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/Kaggle\"\n",
        "#!kaggle datasets list\n",
        "#!mkdir -p /content/drive/MyDrive/Kaggle/digit-recognizer\n",
        "%cd /content/drive/MyDrive/Kaggle/\n",
        "#kaggle competitions download -c digit-recognizer\n",
        "#cp digit-recognize.zip /digit-recognizer/\n",
        "\n",
        "#unzip -q digit-recognizer/digit-recognizer.zip\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa6eLZrdrdRA",
        "outputId": "50b4c20c-f5bc-4798-c04c-b252d6aa66af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Kaggle\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Loan Approval Prediction',\n",
              " '.ipynb_checkpoints',\n",
              " 'kaggle.json',\n",
              " 'config.txt',\n",
              " 'digit-recognizer']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "2vhKpBlcf9JB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9wfHrSOWgKh8",
        "outputId": "4fcff2c2-276e-4d93-c613-34724a445c1c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Kaggle'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data\n",
        "train_data = pd.read_csv('digit-recognizer/train.csv')\n",
        "test_data = pd.read_csv(\"digit-recognizer/test.csv\")"
      ],
      "metadata": {
        "id": "dGcZI5AtgTmP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape, test_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwaI3NSmgziL",
        "outputId": "9319b4f6-bc0d-42db-a176-fbb4b7db28da"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((42000, 785), (28000, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the data\n",
        "y_train = train_data['label'].values\n",
        "X_train = train_data.drop(columns=['label']).values/255\n",
        "X_test = test_data.values/255"
      ],
      "metadata": {
        "id": "Ml4BQWdtgbEz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2,2, figsize=(4,4))\n",
        "axes = axes.flatten()\n",
        "idx = np.random.randint(0,42000,size=4)\n",
        "for i in range(4):\n",
        "    axes[i].imshow(X_train[idx[i],:].reshape(28,28), cmap='gray')\n",
        "    axes[i].axis('off') # hide the axes ticks\n",
        "    axes[i].set_title(str(int(y_train[idx[i]])), color= 'black', fontsize=25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OvJS0dOFhdLg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "2d905f49-492b-43b7-eb72-7de46ac8d68c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# relu activation function\n",
        "# THE fastest vectorized implementation for ReLU\n",
        "def relu(x):\n",
        "    x[x<0]=0\n",
        "    return x"
      ],
      "metadata": {
        "id": "MpoI4b31izrS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def h(X,W,b):\n",
        "    '''\n",
        "    Hypothesis function: simple FNN with 1 hidden layer\n",
        "    Layer 1: input\n",
        "    Layer 2: hidden layer, with a size implied by the arguments W[0], b\n",
        "    Layer 3: output layer, with a size implied by the arguments W[1]\n",
        "    '''\n",
        "    # layer 1 = input layer\n",
        "    a1 = X\n",
        "    # layer 1 (input layer) -> layer 2 (hidden layer)\n",
        "    z1 = np.matmul(X, W[0]) + b[0]\n",
        "\n",
        "    # add one more layer if applicable\n",
        "\n",
        "    # layer 2 activation\n",
        "    a2 = relu(z1)\n",
        "    # layer 2 (hidden layer) -> layer 3 (output layer)\n",
        "    z2 = np.matmul(a2, W[1])\n",
        "    s = np.exp(z2)\n",
        "    total = np.sum(s, axis=1).reshape(-1,1)\n",
        "    sigma = s/total\n",
        "    # the output is a probability for each sample\n",
        "    return sigma"
      ],
      "metadata": {
        "id": "4hlRUDPZoUMb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(X_in,weights):\n",
        "    '''\n",
        "    Un-used cell for demo\n",
        "    activation function for the last FC layer: softmax function\n",
        "    Output: K probabilities represent an estimate of P(y=k|X_in;weights) for k=1,...,K\n",
        "    the weights has shape (n, K)\n",
        "    n: the number of features X_in has\n",
        "    n = X_in.shape[1]\n",
        "    K: the number of classes\n",
        "    K = 10\n",
        "    '''\n",
        "\n",
        "    s = np.exp(np.matmul(X_in,weights))\n",
        "    total = np.sum(s, axis=1).reshape(-1,1)\n",
        "    return s / total"
      ],
      "metadata": {
        "id": "bJoCLBeXsdZk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(y_pred,y_true):\n",
        "    '''\n",
        "    Loss function: cross entropy with an L^2 regularization\n",
        "    y_true: ground truth, of shape (N, )\n",
        "    y_pred: prediction made by the model, of shape (N, K)\n",
        "    N: number of samples in the batch\n",
        "    K: global variable, number of classes\n",
        "    '''\n",
        "    global K\n",
        "    K = 10\n",
        "    N = len(y_true)\n",
        "    # loss_sample stores the cross entropy for each sample in X\n",
        "    # convert y_true from labels to one-hot-vector encoding\n",
        "    y_true_one_hot_vec = (y_true[:,np.newaxis] == np.arange(K))\n",
        "    loss_sample = (np.log(y_pred) * y_true_one_hot_vec).sum(axis=1)\n",
        "    # loss_sample is a dimension (N,) array\n",
        "    # for the final loss, we need take the average\n",
        "    return -np.mean(loss_sample)"
      ],
      "metadata": {
        "id": "nrSN0x_lwQvm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backprop(W,b,X,y,alpha=1e-4):\n",
        "    '''\n",
        "    Step 1: explicit forward pass h(X;W,b)\n",
        "    Step 2: backpropagation for dW and db\n",
        "    '''\n",
        "    K = 10\n",
        "    N = X.shape[0]\n",
        "\n",
        "    ### Step 1:\n",
        "    # layer 1 = input layer\n",
        "    a1 = X\n",
        "    # layer 1 (input layer) -> layer 2 (hidden layer)\n",
        "    z1 = np.matmul(X, W[0]) + b[0]\n",
        "    # layer 2 activation\n",
        "    a2 = relu(z1)\n",
        "\n",
        "    # one more layer\n",
        "\n",
        "    # layer 2 (hidden layer) -> layer 3 (output layer)\n",
        "    z2 = np.matmul(a2, W[1])\n",
        "    s = np.exp(z2)\n",
        "    total = np.sum(s, axis=1).reshape(-1,1)\n",
        "    sigma = s/total\n",
        "\n",
        "    ### Step 2:\n",
        "\n",
        "    # layer 2->layer 3 weights' derivative\n",
        "    # delta2 is \\partial L/partial z2, of shape (N,K)\n",
        "    y_one_hot_vec = (y[:,np.newaxis] == np.arange(K))\n",
        "    delta2 = (sigma - y_one_hot_vec)\n",
        "    grad_W1 = np.matmul(a2.T, delta2)\n",
        "\n",
        "    # layer 1->layer 2 weights' derivative\n",
        "    # delta1 is \\partial a2/partial z1\n",
        "    # layer 2 activation's (weak) derivative is 1*(z1>0)\n",
        "    delta1 = np.matmul(delta2, W[1].T)*(z1>0)\n",
        "    grad_W0 = np.matmul(X.T, delta1)\n",
        "\n",
        "    # Possible student project: extra layer of derivative\n",
        "\n",
        "    # no derivative for layer 1\n",
        "\n",
        "    # the alpha part is the derivative for the regularization\n",
        "    # regularization = 0.5*alpha*(np.sum(W[1]**2) + np.sum(W[0]**2))\n",
        "\n",
        "\n",
        "    dW = [grad_W0/N + alpha*W[0], grad_W1/N + alpha*W[1]]\n",
        "    db = [np.mean(delta1, axis=0)]\n",
        "    # dW[0] is W[0]'s derivative, and dW[1] is W[1]'s derivative; similar for db\n",
        "    return dW, db"
      ],
      "metadata": {
        "id": "Htn8E59VuZiI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper-parameters and network initialization"
      ],
      "metadata": {
        "id": "uXZg283sHVvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eta = 5e-1\n",
        "alpha = 1e-6 # regularization\n",
        "gamma = 0.99 # RMSprop\n",
        "eps = 1e-3 # RMSprop\n",
        "num_iter = 1000 # number of iterations of gradient descent\n",
        "n_H = 256 # number of neurons in the hidden layer\n",
        "n = X_train.shape[1] # number of pixels in an image\n",
        "K = 10"
      ],
      "metadata": {
        "id": "Bf-yiEG_Hycl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialization\n",
        "np.random.seed(1127825)\n",
        "W = [1e-1*np.random.randn(n, n_H), 1e-1*np.random.randn(n_H, K)]\n",
        "b = [np.random.randn(n_H)]\n"
      ],
      "metadata": {
        "id": "bht8kcgXIBED"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "gW0 = gW1 = gb0 = 1\n",
        "\n",
        "for i in range(num_iter):\n",
        "    dW, db = backprop(W,b,X_train,y_train,alpha)\n",
        "\n",
        "    gW0 = gamma*gW0 + (1-gamma)*np.sum(dW[0]**2)\n",
        "    etaW0 = eta/np.sqrt(gW0 + eps)\n",
        "    W[0] -= etaW0 * dW[0]\n",
        "\n",
        "    gW1 = gamma*gW1 + (1-gamma)*np.sum(dW[1]**2)\n",
        "    etaW1 = eta/np.sqrt(gW1 + eps)\n",
        "    W[1] -= etaW1 * dW[1]\n",
        "\n",
        "    gb0 = gamma*gb0 + (1-gamma)*np.sum(db[0]**2)\n",
        "    etab0 = eta/np.sqrt(gb0 + eps)\n",
        "    b[0] -= etab0 * db[0]\n",
        "\n",
        "    if i % 500 == 0:\n",
        "        # sanity check 1\n",
        "        y_pred = h(X_train,W,b)\n",
        "        print(\"Cross-entropy loss after\", i+1, \"iterations is {:.8}\".format(\n",
        "              loss(y_pred,y_train)))\n",
        "        print(\"Training accuracy after\", i+1, \"iterations is {:.4%}\".format(\n",
        "              np.mean(np.argmax(y_pred, axis=1)== y_train)))\n",
        "\n",
        "        # sanity check 2\n",
        "        print(\"gW0={:.4f} gW1={:.4f} gb0={:.4f}\\netaW0={:.4f} etaW1={:.4f} etab0={:.4f}\"\n",
        "              .format(gW0, gW1, gb0, etaW0, etaW1, etab0))\n",
        "\n",
        "        # sanity check 3\n",
        "        print(\"|dW0|={:.5f} |dW1|={:.5f} |db0|={:.5f}\"\n",
        "             .format(np.linalg.norm(dW[0]), np.linalg.norm(dW[1]), np.linalg.norm(db[0])), \"\\n\")\n",
        "\n",
        "        # reset RMSprop\n",
        "        gW0 = gW1 = gb0 = 1\n",
        "\n",
        "y_pred_final = h(X_train,W,b)\n",
        "print(\"Final cross-entropy loss is {:.8}\".format(loss(y_pred_final,y_train)))\n",
        "print(\"Final training accuracy is {:.4%}\".format(np.mean(np.argmax(y_pred_final, axis=1)== y_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "fm72i6kLICJh",
        "outputId": "be7918ed-47c3-42b2-e6a3-726d7100fa05"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-entropy loss after 1 iterations is 7.6743264\n",
            "Training accuracy after 1 iterations is 24.9262%\n",
            "gW0=1.0839 gW1=1.3825 gb0=0.9923\n",
            "etaW0=0.4800 etaW1=0.4251 etab0=0.5017\n",
            "|dW0|=3.06418 |dW1|=6.26530 |db0|=0.48001 \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-19f4df73aef6>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(W, b, X, y, alpha)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# layer 1 (input layer) -> layer 2 (hidden layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m# layer 2 activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}