{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YvE1PbupiFlTCa2bHtn9tXHAFeMCCJlD",
      "authorship_tag": "ABX9TyPRVPSrVyeA9K5q4W6+JnGI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gRedDeer/kaggle_notebooks/blob/main/Mnist_digit_cnn_fn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/Kaggle\"\n",
        "#!kaggle datasets list\n",
        "#!mkdir -p /content/drive/MyDrive/Kaggle/digit-recognizer\n",
        "%cd /content/drive/MyDrive/Kaggle/\n",
        "#kaggle competitions download -c digit-recognizer\n",
        "#cp digit-recognize.zip /digit-recognizer/\n",
        "\n",
        "#unzip -q digit-recognizer/digit-recognizer.zip\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa6eLZrdrdRA",
        "outputId": "185b61cd-aa94-4723-e32e-00223ca5ee91"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Kaggle\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Loan Approval Prediction',\n",
              " '.ipynb_checkpoints',\n",
              " 'kaggle.json',\n",
              " 'config.txt',\n",
              " 'digit-recognizer']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "2vhKpBlcf9JB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9wfHrSOWgKh8",
        "outputId": "6d52a86a-93de-47df-966d-73669bd1d72b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Kaggle'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data\n",
        "train_data = pd.read_csv('digit-recognizer/train.csv')\n",
        "test_data = pd.read_csv(\"digit-recognizer/test.csv\")"
      ],
      "metadata": {
        "id": "dGcZI5AtgTmP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape, test_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwaI3NSmgziL",
        "outputId": "9f5d2122-c214-4c15-a94f-5d8fb3d1d9d0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((42000, 785), (28000, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the data\n",
        "y_train = train_data['label'].values\n",
        "X_train = train_data.drop(columns=['label']).values/255\n",
        "X_test = test_data.values/255"
      ],
      "metadata": {
        "id": "Ml4BQWdtgbEz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2,2, figsize=(4,4))\n",
        "axes = axes.flatten()\n",
        "idx = np.random.randint(0,42000,size=4)\n",
        "for i in range(4):\n",
        "    axes[i].imshow(X_train[idx[i],:].reshape(28,28), cmap='gray')\n",
        "    axes[i].axis('off') # hide the axes ticks\n",
        "    axes[i].set_title(str(int(y_train[idx[i]])), color= 'black', fontsize=25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OvJS0dOFhdLg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "feded16f-dd07-4b20-db07-2cb1c505bcae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# relu activation function\n",
        "# THE fastest vectorized implementation for ReLU\n",
        "def relu(x):\n",
        "    x[x<0]=0\n",
        "    return x"
      ],
      "metadata": {
        "id": "MpoI4b31izrS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def h(X,W,b):\n",
        "    '''\n",
        "    Hypothesis function: simple FNN with 1 hidden layer\n",
        "    Layer 1: input\n",
        "    Layer 2: hidden layer, with a size implied by the arguments W[0], b\n",
        "    Layer 3: output layer, with a size implied by the arguments W[1]\n",
        "    '''\n",
        "    # layer 1 = input layer\n",
        "    a1 = X\n",
        "    # layer 1 (input layer) -> layer 2 (hidden layer)\n",
        "    z1 = np.matmul(X, W[0]) + b[0]\n",
        "\n",
        "    # add one more layer if applicable\n",
        "\n",
        "    # layer 2 activation\n",
        "    a2 = relu(z1)\n",
        "    # layer 2 (hidden layer) -> layer 3 (output layer)\n",
        "    z2 = np.matmul(a2, W[1])\n",
        "    s = np.exp(z2)\n",
        "    total = np.sum(s, axis=1).reshape(-1,1)\n",
        "    sigma = s/total\n",
        "    # the output is a probability for each sample\n",
        "    return sigma"
      ],
      "metadata": {
        "id": "4hlRUDPZoUMb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(X_in,weights):\n",
        "    '''\n",
        "    Un-used cell for demo\n",
        "    activation function for the last FC layer: softmax function\n",
        "    Output: K probabilities represent an estimate of P(y=k|X_in;weights) for k=1,...,K\n",
        "    the weights has shape (n, K)\n",
        "    n: the number of features X_in has\n",
        "    n = X_in.shape[1]\n",
        "    K: the number of classes\n",
        "    K = 10\n",
        "    '''\n",
        "\n",
        "    s = np.exp(np.matmul(X_in,weights))\n",
        "    total = np.sum(s, axis=1).reshape(-1,1)\n",
        "    return s / total"
      ],
      "metadata": {
        "id": "bJoCLBeXsdZk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(y_pred,y_true):\n",
        "    '''\n",
        "    Loss function: cross entropy with an L^2 regularization\n",
        "    y_true: ground truth, of shape (N, )\n",
        "    y_pred: prediction made by the model, of shape (N, K)\n",
        "    N: number of samples in the batch\n",
        "    K: global variable, number of classes\n",
        "    '''\n",
        "    global K\n",
        "    K = 10\n",
        "    N = len(y_true)\n",
        "    # loss_sample stores the cross entropy for each sample in X\n",
        "    # convert y_true from labels to one-hot-vector encoding\n",
        "    y_true_one_hot_vec = (y_true[:,np.newaxis] == np.arange(K))\n",
        "    loss_sample = (np.log(y_pred) * y_true_one_hot_vec).sum(axis=1)\n",
        "    # loss_sample is a dimension (N,) array\n",
        "    # for the final loss, we need take the average\n",
        "    return -np.mean(loss_sample)"
      ],
      "metadata": {
        "id": "nrSN0x_lwQvm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backprop(W,b,X,y,alpha=1e-4):\n",
        "    '''\n",
        "    Step 1: explicit forward pass h(X;W,b)\n",
        "    Step 2: backpropagation for dW and db\n",
        "    '''\n",
        "    K = 10\n",
        "    N = X.shape[0]\n",
        "\n",
        "    ### Step 1:\n",
        "    # layer 1 = input layer\n",
        "    a1 = X\n",
        "    # layer 1 (input layer) -> layer 2 (hidden layer)\n",
        "    z1 = np.matmul(X, W[0]) + b[0]\n",
        "    # layer 2 activation\n",
        "    a2 = relu(z1)\n",
        "\n",
        "    # one more layer\n",
        "\n",
        "    # layer 2 (hidden layer) -> layer 3 (output layer)\n",
        "    z2 = np.matmul(a2, W[1])\n",
        "    s = np.exp(z2)\n",
        "    total = np.sum(s, axis=1).reshape(-1,1)\n",
        "    sigma = s/total\n",
        "\n",
        "    ### Step 2:\n",
        "\n",
        "    # layer 2->layer 3 weights' derivative\n",
        "    # delta2 is \\partial L/partial z2, of shape (N,K)\n",
        "    y_one_hot_vec = (y[:,np.newaxis] == np.arange(K))\n",
        "    delta2 = (sigma - y_one_hot_vec)\n",
        "    grad_W1 = np.matmul(a2.T, delta2)\n",
        "\n",
        "    # layer 1->layer 2 weights' derivative\n",
        "    # delta1 is \\partial a2/partial z1\n",
        "    # layer 2 activation's (weak) derivative is 1*(z1>0)\n",
        "    delta1 = np.matmul(delta2, W[1].T)*(z1>0)\n",
        "    grad_W0 = np.matmul(X.T, delta1)\n",
        "\n",
        "    # Possible student project: extra layer of derivative\n",
        "\n",
        "    # no derivative for layer 1\n",
        "\n",
        "    # the alpha part is the derivative for the regularization\n",
        "    # regularization = 0.5*alpha*(np.sum(W[1]**2) + np.sum(W[0]**2))\n",
        "\n",
        "\n",
        "    dW = [grad_W0/N + alpha*W[0], grad_W1/N + alpha*W[1]]\n",
        "    db = [np.mean(delta1, axis=0)]\n",
        "    # dW[0] is W[0]'s derivative, and dW[1] is W[1]'s derivative; similar for db\n",
        "    return dW, db"
      ],
      "metadata": {
        "id": "Htn8E59VuZiI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper-parameters and network initialization"
      ],
      "metadata": {
        "id": "uXZg283sHVvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eta = 5e-1\n",
        "alpha = 1e-6 # regularization\n",
        "gamma = 0.99 # RMSprop\n",
        "eps = 1e-3 # RMSprop\n",
        "num_iter = 1000 # number of iterations of gradient descent\n",
        "n_H = 256 # number of neurons in the hidden layer\n",
        "n = X_train.shape[1] # number of pixels in an image\n",
        "K = 10"
      ],
      "metadata": {
        "id": "Bf-yiEG_Hycl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialization\n",
        "np.random.seed(1127825)\n",
        "W = [1e-1*np.random.randn(n, n_H), 1e-1*np.random.randn(n_H, K)]\n",
        "b = [np.random.randn(n_H)]\n"
      ],
      "metadata": {
        "id": "bht8kcgXIBED"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "gW0 = gW1 = gb0 = 1\n",
        "\n",
        "for i in range(num_iter):\n",
        "    dW, db = backprop(W,b,X_train,y_train,alpha)\n",
        "\n",
        "    gW0 = gamma*gW0 + (1-gamma)*np.sum(dW[0]**2)\n",
        "    etaW0 = eta/np.sqrt(gW0 + eps)\n",
        "    W[0] -= etaW0 * dW[0]\n",
        "\n",
        "    gW1 = gamma*gW1 + (1-gamma)*np.sum(dW[1]**2)\n",
        "    etaW1 = eta/np.sqrt(gW1 + eps)\n",
        "    W[1] -= etaW1 * dW[1]\n",
        "\n",
        "    gb0 = gamma*gb0 + (1-gamma)*np.sum(db[0]**2)\n",
        "    etab0 = eta/np.sqrt(gb0 + eps)\n",
        "    b[0] -= etab0 * db[0]\n",
        "\n",
        "    if i % 500 == 0:\n",
        "        # sanity check 1\n",
        "        y_pred = h(X_train,W,b)\n",
        "        print(\"Cross-entropy loss after\", i+1, \"iterations is {:.8}\".format(\n",
        "              loss(y_pred,y_train)))\n",
        "        print(\"Training accuracy after\", i+1, \"iterations is {:.4%}\".format(\n",
        "              np.mean(np.argmax(y_pred, axis=1)== y_train)))\n",
        "\n",
        "        # sanity check 2\n",
        "        print(\"gW0={:.4f} gW1={:.4f} gb0={:.4f}\\netaW0={:.4f} etaW1={:.4f} etab0={:.4f}\"\n",
        "              .format(gW0, gW1, gb0, etaW0, etaW1, etab0))\n",
        "\n",
        "        # sanity check 3\n",
        "        print(\"|dW0|={:.5f} |dW1|={:.5f} |db0|={:.5f}\"\n",
        "             .format(np.linalg.norm(dW[0]), np.linalg.norm(dW[1]), np.linalg.norm(db[0])), \"\\n\")\n",
        "\n",
        "        # reset RMSprop\n",
        "        gW0 = gW1 = gb0 = 1\n",
        "\n",
        "y_pred_final = h(X_train,W,b)\n",
        "print(\"Final cross-entropy loss is {:.8}\".format(loss(y_pred_final,y_train)))\n",
        "print(\"Final training accuracy is {:.4%}\".format(np.mean(np.argmax(y_pred_final, axis=1)== y_train)))"
      ],
      "metadata": {
        "id": "fm72i6kLICJh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "bc58f044-3fca-41d6-b6fb-426da50556aa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-entropy loss after 1 iterations is 7.6743264\n",
            "Training accuracy after 1 iterations is 24.9262%\n",
            "gW0=1.0839 gW1=1.3825 gb0=0.9923\n",
            "etaW0=0.4800 etaW1=0.4251 etab0=0.5017\n",
            "|dW0|=3.06418 |dW1|=6.26530 |db0|=0.48001 \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-19f4df73aef6>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(W, b, X, y, alpha)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# layer 1 (input layer) -> layer 2 (hidden layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m# layer 2 activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions\n",
        "y_pred_test = np.argmax(h(X_test,W,b), axis=1)"
      ],
      "metadata": {
        "id": "ThH3Vke8PYLe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating submission using pandas for grading\n",
        "submission = pd.DataFrame({'ImageId': range(1,len(X_test)+1) ,'Label': y_pred_test })\n",
        "submission.to_csv(\"simplemnist_result.csv\",index=False)"
      ],
      "metadata": {
        "id": "jnv1zRfxPa3S"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}